package main

import (
	"bufio"
	"database/sql"
	"flag"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"time"

	"KamaitachiGo/pkg/json"

	_ "modernc.org/sqlite"
)

// FinanceRecord è´¢æŠ¥è®°å½•
type FinanceRecord struct {
	StockCode             string
	MarketCode            string
	SubjectKey            string
	StockName             string
	ReportDate            int64
	EndDate               string
	Year                  string
	Period                string
	OperatingIncome       float64
	ParentHolderNetProfit float64
	Category              string
	Topic                 string
}

var (
	dbPath     = flag.String("db", "./data/finance.db", "SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„")
	sqlDir     = flag.String("dir", "../f10sql", "SQLæ–‡ä»¶ç›®å½•")
	batchSize  = flag.Int("batch", 1000, "æ‰¹é‡æ’å…¥å¤§å°")
	maxRecords = flag.Int("max", 0, "æœ€å¤§å¯¼å…¥è®°å½•æ•°ï¼ˆ0=å…¨éƒ¨ï¼‰")
)

func main() {
	flag.Parse()

	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘   è´¢æŠ¥æ•°æ®å¯¼å…¥å·¥å…· - SQLiteç‰ˆæœ¬      â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println()

	// 1. è¿æ¥SQLite
	fmt.Printf("ğŸ“‚ æ•°æ®åº“: %s\n", *dbPath)
	db, err := initDatabase(*dbPath)
	if err != nil {
		log.Fatal("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥:", err)
	}
	defer db.Close()

	// 2. æŸ¥æ‰¾SQLæ–‡ä»¶
	fmt.Printf("ğŸ“ æ‰«æç›®å½•: %s\n", *sqlDir)
	sqlFiles, err := findSQLFiles(*sqlDir)
	if err != nil {
		log.Fatal("æŸ¥æ‰¾SQLæ–‡ä»¶å¤±è´¥:", err)
	}

	if len(sqlFiles) == 0 {
		log.Fatal("æœªæ‰¾åˆ°SQLæ–‡ä»¶")
	}

	fmt.Printf("âœ… æ‰¾åˆ° %d ä¸ªSQLæ–‡ä»¶\n\n", len(sqlFiles))

	// 3. å¯¼å…¥æ•°æ®
	totalRecords := 0
	startTime := time.Now()

	for i, sqlFile := range sqlFiles {
		fileName := filepath.Base(sqlFile)
		fmt.Printf("[%d/%d] å¤„ç†: %s\n", i+1, len(sqlFiles), fileName)

		count, err := importSQLFile(db, sqlFile, *batchSize, *maxRecords-totalRecords)
		if err != nil {
			log.Printf("  âš ï¸  è­¦å‘Š: %v\n", err)
			continue
		}

		totalRecords += count
		fmt.Printf("  âœ… å¯¼å…¥ %d æ¡è®°å½•\n", count)

		if *maxRecords > 0 && totalRecords >= *maxRecords {
			fmt.Printf("\nâš ï¸  å·²è¾¾åˆ°æœ€å¤§è®°å½•æ•°é™åˆ¶: %d\n", *maxRecords)
			break
		}
	}

	elapsed := time.Since(startTime)

	// 4. æ˜¾ç¤ºç»Ÿè®¡
	fmt.Println()
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘           å¯¼å…¥å®Œæˆç»Ÿè®¡               â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("âœ… æ€»è®°å½•æ•°: %d\n", totalRecords)
	fmt.Printf("â±ï¸  æ€»è€—æ—¶: %s\n", elapsed)
	fmt.Printf("ğŸš€ é€Ÿåº¦: %.0f æ¡/ç§’\n", float64(totalRecords)/elapsed.Seconds())
	fmt.Println()

	// 5. éªŒè¯æ•°æ®
	verifyData(db)
}

// initDatabase åˆå§‹åŒ–æ•°æ®åº“
func initDatabase(dbPath string) (*sql.DB, error) {
	// åˆ›å»ºç›®å½•
	dir := filepath.Dir(dbPath)
	if err := os.MkdirAll(dir, 0755); err != nil {
		return nil, err
	}

	// è¿æ¥æ•°æ®åº“
	db, err := sql.Open("sqlite", dbPath)
	if err != nil {
		return nil, err
	}

	// åˆ›å»ºè¡¨
	_, err = db.Exec(`
		CREATE TABLE IF NOT EXISTS finance_data (
			id INTEGER PRIMARY KEY AUTOINCREMENT,
			stock_code TEXT NOT NULL,
			market_code TEXT NOT NULL,
			subject_key TEXT NOT NULL,
			stock_name TEXT,
			report_date INTEGER NOT NULL,
			end_date TEXT,
			year TEXT,
			period TEXT,
			operating_income REAL,
			parent_holder_net_profit REAL,
			category TEXT DEFAULT 'stock',
			topic TEXT DEFAULT 'stock_a_listing_pool'
		);

		CREATE INDEX IF NOT EXISTS idx_subject_date ON finance_data(subject_key, report_date DESC);
		CREATE INDEX IF NOT EXISTS idx_topic ON finance_data(topic);
		CREATE INDEX IF NOT EXISTS idx_stock_code ON finance_data(stock_code);
	`)
	if err != nil {
		return nil, err
	}

	// æ€§èƒ½ä¼˜åŒ–
	db.Exec("PRAGMA journal_mode=WAL")
	db.Exec("PRAGMA synchronous=NORMAL")
	db.Exec("PRAGMA cache_size=10000")
	db.SetMaxOpenConns(1)

	fmt.Println("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
	return db, nil
}

// findSQLFiles æŸ¥æ‰¾SQLæ–‡ä»¶
func findSQLFiles(dir string) ([]string, error) {
	var files []string

	err := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		if !info.IsDir() && strings.HasSuffix(path, ".sql") {
			files = append(files, path)
		}
		return nil
	})

	return files, err
}

// importSQLFile å¯¼å…¥SQLæ–‡ä»¶
func importSQLFile(db *sql.DB, sqlFile string, batchSize int, maxRecords int) (int, error) {
	file, err := os.Open(sqlFile)
	if err != nil {
		return 0, err
	}
	defer file.Close()

	// å‡†å¤‡æ’å…¥è¯­å¥
	stmt, err := db.Prepare(`
		INSERT INTO finance_data 
		(stock_code, market_code, subject_key, stock_name, report_date, 
		 end_date, year, period, operating_income, parent_holder_net_profit, category, topic)
		VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`)
	if err != nil {
		return 0, err
	}
	defer stmt.Close()

	// æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…INSERTè¯­å¥
	// VALUES ('stock_code', '{json}', 'update_time', version)
	insertPattern := regexp.MustCompile(`VALUES\s*\('([^']+)',\s*'(\{[^}]+\}[^']*)',\s*'[^']*',\s*\d+\)`)

	scanner := bufio.NewScanner(file)
	buf := make([]byte, 10*1024*1024)  // 10MB buffer
	scanner.Buffer(buf, 100*1024*1024) // æœ€å¤§100MB

	totalCount := 0
	batchCount := 0
	tx, _ := db.Begin()

	for scanner.Scan() {
		line := scanner.Text()

		// æŸ¥æ‰¾INSERTè¯­å¥
		matches := insertPattern.FindStringSubmatch(line)
		if len(matches) < 3 {
			continue
		}

		stockCode := matches[1]
		jsonData := matches[2]

		// è§£æJSONæ—¶é—´åºåˆ—æ•°æ®
		records, err := parseTimeSeriesData(stockCode, jsonData)
		if err != nil {
			log.Printf("  âš ï¸  è§£æå¤±è´¥ [%s]: %v\n", stockCode, err)
			continue
		}

		// æ‰¹é‡æ’å…¥
		for _, record := range records {
			_, err := tx.Stmt(stmt).Exec(
				record.StockCode,
				record.MarketCode,
				record.SubjectKey,
				record.StockName,
				record.ReportDate,
				record.EndDate,
				record.Year,
				record.Period,
				record.OperatingIncome,
				record.ParentHolderNetProfit,
				record.Category,
				record.Topic,
			)
			if err != nil {
				log.Printf("  âš ï¸  æ’å…¥å¤±è´¥: %v\n", err)
				continue
			}

			totalCount++
			batchCount++

			// æ‰¹é‡æäº¤
			if batchCount >= batchSize {
				if err := tx.Commit(); err != nil {
					return totalCount, err
				}
				tx, _ = db.Begin()
				batchCount = 0
			}

			// æ£€æŸ¥æœ€å¤§è®°å½•æ•°
			if maxRecords > 0 && totalCount >= maxRecords {
				tx.Commit()
				return totalCount, nil
			}
		}
	}

	// æäº¤å‰©ä½™çš„
	if err := tx.Commit(); err != nil {
		return totalCount, err
	}

	if err := scanner.Err(); err != nil {
		return totalCount, err
	}

	return totalCount, nil
}

// parseTimeSeriesData è§£ææ—¶é—´åºåˆ—JSONæ•°æ®
func parseTimeSeriesData(stockCode string, jsonStr string) ([]*FinanceRecord, error) {
	// SQLä¸­çš„JSONæ ¼å¼ä¸æ ‡å‡†ï¼š{1234567:[...], ...}
	// éœ€è¦å°†æ•°å­—keyåŠ ä¸Šå¼•å·ï¼š{"1234567":[...], ...}
	fixedJSON := fixJSONKeys(jsonStr)

	// è§£æJSON: {timestamp: [field1, field2, ...], ...}
	var timeSeriesData map[string][]interface{}

	if err := json.Unmarshal([]byte(fixedJSON), &timeSeriesData); err != nil {
		return nil, fmt.Errorf("JSONè§£æå¤±è´¥: %v", err)
	}

	var records []*FinanceRecord

	for timestampStr, values := range timeSeriesData {
		// è§£ææ—¶é—´æˆ³
		var timestamp int64
		fmt.Sscanf(timestampStr, "%d", &timestamp)

		// æå–å­—æ®µï¼ˆæ ¹æ®å®é™…SQLæ•°æ®ç»“æ„ï¼‰
		if len(values) < 10 {
			continue
		}

		record := &FinanceRecord{
			StockCode:  stockCode,
			ReportDate: timestamp,
			Category:   "stock",
			Topic:      "stock_a_listing_pool",
		}

		// æå–å­—æ®µå€¼
		if v, ok := values[1].(string); ok {
			record.EndDate = v
		}
		if v, ok := values[2].(string); ok {
			record.Year = v
		}
		if v, ok := values[3].(string); ok {
			record.Period = v
		}
		if v, ok := values[4].(float64); ok {
			record.OperatingIncome = v
		}
		// parent_holder_net_profit çš„ç´¢å¼•éœ€è¦æ ¹æ®å®é™…æ•°æ®ç¡®å®š
		// æš‚æ—¶ä½¿ç”¨ç´¢å¼• 5-15 ä¹‹é—´å°è¯•
		for i := 5; i < len(values) && i < 15; i++ {
			if v, ok := values[i].(float64); ok && v > 0 && record.ParentHolderNetProfit == 0 {
				record.ParentHolderNetProfit = v
				break
			}
		}

		// æ¨æ–­å¸‚åœºä»£ç ï¼ˆ33=æ·±åœ³, 17=ä¸Šæµ·, ç­‰ï¼‰
		record.MarketCode = inferMarketCode(stockCode)
		record.SubjectKey = fmt.Sprintf("%s:%s", record.MarketCode, stockCode)

		records = append(records, record)
	}

	return records, nil
}

// fixJSONKeys ä¿®å¤JSONæ ¼å¼
func fixJSONKeys(jsonStr string) string {
	// 1. å°†è½¬ä¹‰çš„å¼•å·æ›¿æ¢ä¸ºæ­£å¸¸å¼•å·ï¼š\" â†’ "
	fixed := strings.ReplaceAll(jsonStr, `\"`, `"`)

	// 2. å°†æ•°å­—keyåŠ å¼•å·ï¼š{1234567:[...]} â†’ {"1234567":[...]}
	re := regexp.MustCompile(`(\{|,)(\d+):`)
	fixed = re.ReplaceAllString(fixed, `$1"$2":`)

	return fixed
}

// inferMarketCode æ¨æ–­å¸‚åœºä»£ç 
func inferMarketCode(stockCode string) string {
	if strings.HasPrefix(stockCode, "00") || strings.HasPrefix(stockCode, "30") {
		return "33" // æ·±åœ³
	} else if strings.HasPrefix(stockCode, "60") {
		return "17" // ä¸Šæµ·
	}
	return "33" // é»˜è®¤
}

// verifyData éªŒè¯æ•°æ®
func verifyData(db *sql.DB) {
	fmt.Println("ğŸ” éªŒè¯æ•°æ®...")

	// ç»Ÿè®¡è®°å½•æ•°
	var count int
	db.QueryRow("SELECT COUNT(*) FROM finance_data").Scan(&count)
	fmt.Printf("  ğŸ“Š æ€»è®°å½•æ•°: %d\n", count)

	// ç»Ÿè®¡è‚¡ç¥¨æ•°
	var stockCount int
	db.QueryRow("SELECT COUNT(DISTINCT stock_code) FROM finance_data").Scan(&stockCount)
	fmt.Printf("  ğŸ“ˆ è‚¡ç¥¨æ•°é‡: %d\n", stockCount)

	// æ˜¾ç¤ºæ ·æœ¬æ•°æ®
	rows, err := db.Query(`
		SELECT subject_key, stock_name, end_date, operating_income, parent_holder_net_profit
		FROM finance_data
		ORDER BY operating_income DESC
		LIMIT 5
	`)
	if err == nil {
		defer rows.Close()
		fmt.Println("\n  ğŸ“Š è¥ä¸šæ”¶å…¥TOP5:")
		for rows.Next() {
			var subjectKey, stockName, endDate string
			var income, profit float64
			rows.Scan(&subjectKey, &stockName, &endDate, &income, &profit)
			if stockName == "" {
				stockName = subjectKey
			}
			fmt.Printf("    %s - %.2fäº¿å…ƒ\n", stockName, income/100000000)
		}
	}

	fmt.Println()
}
